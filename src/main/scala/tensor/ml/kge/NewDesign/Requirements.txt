abstract class Triples 
	- loading datasets
	- querying all entities
	- querying all relationships

abstract class CrossValidator	
(a) 1 file = test + training => we have to separate it ourselves e.g. cross validation (Hold out, F-fold cross validation, K-fold, random subsampling, bootstrapping)
	- generate training and test datasets
		
Abstract class Convertor => [different classes will implement this -> simple convertor, customized convertor,

There are two possiblities which could be implemented:
(b) 2 files => test & training are given as two separate files. 
   
	- convertor: triples to numerical values
		- numerical Spark-DataFrame with columns of (Long, Long, Long)
		- convertors for case (A) should consider the internal structure of the original data sets in files
		
	- inverse-convertor: converting back from numerical presentation
	- querying what is what after transformation to numeric values
	- negative sampler
	- comparing similarities between entities/relationships




class PerformanceTesting
	- measures 
		- top ranking (@ X)
		- precision and recall
		- F-score
		- AUC
	
class Parameters [keeps track of each algorithm paprameters] ???		
abstract class Algorithm
	- implementation
	- logging
	- meta-parameter manipulation
	- timing 
	
abstract class Prediction
	- 
	
	

PipeLine:

load data sets -> 
1.* raw strings -> numerical convertor -> cross validation -> algorithm
2. raw strings + cross validated -> numerical convertor -> algorithm	
3.* already numerical datasets -> cross validation -> algorithm
4. already numerical datasets + cross validated -> algorithm 		
	
================== Other option ========================= 
=========================================================
trait Triples
trait AlgorithmicRequirements

class TriplesCaseB extend Triples
class TriplesCaseA extend Triples & AlgorithmicRquriementes

TripleCaseA extends TriplesCaseB